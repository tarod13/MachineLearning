{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "y_total = np.genfromtxt(\"msd_genre_dataset.txt\",dtype =None,usecols=0,comments=None,delimiter=',',skip_header=10)\n",
    "x_total = np.genfromtxt(\"msd_genre_dataset.txt\",comments=None,delimiter=',',skip_header=10)[:,4:]\n",
    "\n",
    "generos = [b'metal',b'punk',b'dance and electronica']\n",
    "\n",
    "y_raw = []\n",
    "x_raw = []\n",
    "for i in range(0,y_total.size):\n",
    "    if y_total[i] in generos:\n",
    "        y_raw.append(y_total[i])\n",
    "        x_raw.append(x_total[i])\n",
    "        \n",
    "y_raw = np.asarray(y_raw)\n",
    "x_raw = np.asarray(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "x_normalizado = (x_raw - np.mean(x_raw,axis=0))/np.std(x_raw,axis=0)\n",
    "\n",
    "# PCA\n",
    "proporcion_varianza = 0\n",
    "n_componentes = 0\n",
    "while proporcion_varianza < 0.90:\n",
    "    n_componentes = n_componentes + 1\n",
    "    pca = PCA(n_components=n_componentes)\n",
    "    pca = pca.fit(x_normalizado)\n",
    "    proporcion_varianza = np.sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "suma_acumulada_varianza = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "\n",
    "x_preprocesamiento = pca.fit_transform(x_normalizado)\n",
    "xy_preprocesamiento = np.append(x_preprocesamiento,np.array([y_raw]).T,axis=1)\n",
    "\n",
    "np.random.shuffle(xy_preprocesamiento)\n",
    "n_prueba = round(0.3*y_raw.size)\n",
    "datos_prueba = xy_preprocesamiento[0:n_prueba,:]\n",
    "x_prueba = datos_prueba[:,0:-1].astype(np.float64)\n",
    "y_prueba = datos_prueba[:,-1]\n",
    "datos_entrenamiento = xy_preprocesamiento[n_prueba+1:,:]\n",
    "x_entrenamiento = datos_entrenamiento[:,0:-1].astype(np.float64)\n",
    "y_entrenamiento = datos_entrenamiento[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etiquetas_prueba = np.where(y_prueba == generos[2], np.ones(y_prueba.shape), np.zeros(y_prueba.shape))\n",
    "etiquetas_entrenamiento = np.where(y_entrenamiento == generos[2], np.ones(y_entrenamiento.shape), np.zeros(y_entrenamiento.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entrenamiento_logreg = np.append(np.array([np.ones(y_entrenamiento.size)]).T,x_entrenamiento,axis=1)\n",
    "clasificador_logreg = LogisticRegression(solver='sag',max_iter=1000)\n",
    "clasificador_logreg = clasificador_logreg.fit(x_entrenamiento_logreg,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parametros_w_logreg = clasificador_logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02425732,  0.8335613 , -0.28693165, -0.27905244, -0.62083404,\n",
       "        -0.1189478 , -0.74095523, -0.31207213, -0.00734011,  0.20180361,\n",
       "        -0.11454605, -0.09400964, -0.16835191, -0.11707359, -0.11677364,\n",
       "         0.34938764,  0.14483699, -0.03706737,  0.04351406]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros_w_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etiquetas_regresion = 1/(1+np.exp(np.inner(-parametros_w_logreg,x_entrenamiento))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etiquetas_regresion[6590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yy = clasificador_logreg.predict(x_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prueba_logreg = np.append(np.array([np.ones(y_prueba.size)]).T,x_prueba,axis=1)\n",
    "puntaje = clasificador_logreg.score(x_prueba_logreg,etiquetas_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85411917942038429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([365], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificador_logreg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matriz_covarianza = np.cov(x_prueba_logreg.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
