{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import norm\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "y_total = np.genfromtxt(\"msd_genre_dataset.txt\",dtype =None,usecols=0,comments=None,delimiter=',',skip_header=10)\n",
    "x_total = np.genfromtxt(\"msd_genre_dataset.txt\",comments=None,delimiter=',',skip_header=10)[:,4:]\n",
    "\n",
    "generos = [b'metal',b'punk',b'dance and electronica']\n",
    "\n",
    "y_raw = []\n",
    "x_raw = []\n",
    "for i in range(0,y_total.size):\n",
    "    if y_total[i] in generos:\n",
    "        y_raw.append(y_total[i])\n",
    "        x_raw.append(x_total[i])\n",
    "        \n",
    "y_raw = np.asarray(y_raw)\n",
    "x_raw = np.asarray(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "x_normalizado = (x_raw - np.mean(x_raw,axis=0))/np.std(x_raw,axis=0)\n",
    "\n",
    "# PCA\n",
    "proporcion_varianza = 0\n",
    "n_componentes = 0\n",
    "while proporcion_varianza < 0.90:\n",
    "    n_componentes = n_componentes + 1\n",
    "    pca = PCA(n_components=n_componentes)\n",
    "    pca = pca.fit(x_normalizado)\n",
    "    proporcion_varianza = np.sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "suma_acumulada_varianza = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "\n",
    "x_preprocesamiento = pca.fit_transform(x_normalizado)\n",
    "xy_preprocesamiento = np.append(x_preprocesamiento,np.array([y_raw]).T,axis=1)\n",
    "\n",
    "# Separacion de datos para prueba y entrenamiento\n",
    "proporcion_prueba = 0.1\n",
    "np.random.shuffle(xy_preprocesamiento)\n",
    "n_prueba = round(proporcion_prueba*y_raw.size)\n",
    "n_entrenamiento = y_raw.size - n_prueba\n",
    "datos_prueba = xy_preprocesamiento[0:n_prueba,:]\n",
    "x_prueba = datos_prueba[:,0:-1].astype(np.float64)\n",
    "y_prueba = datos_prueba[:,-1]\n",
    "datos_entrenamiento = xy_preprocesamiento[n_prueba:,:]\n",
    "x_entrenamiento = datos_entrenamiento[:,0:-1].astype(np.float64)\n",
    "y_entrenamiento = datos_entrenamiento[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etiquetas_prueba = np.where(y_prueba == generos[2], np.ones(n_prueba), np.zeros(n_prueba))\n",
    "etiquetas_entrenamiento = np.where(y_entrenamiento == generos[2], np.ones(n_entrenamiento), np.zeros(n_entrenamiento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_entrenamiento_logreg = np.append(np.array([np.ones(n_entrenamiento)]).T,x_entrenamiento,axis=1)\n",
    "clasificador_logreg = LogisticRegression(solver='sag',max_iter=1000)\n",
    "clasificador_logreg = clasificador_logreg.fit(x_entrenamiento_logreg,etiquetas_entrenamiento)\n",
    "\n",
    "clasificador_logreg_sin_var = LogisticRegression(solver='sag',max_iter=10000)\n",
    "clasificador_logreg_sin_var = clasificador_logreg_sin_var.fit(np.array([np.ones(n_entrenamiento)]).T,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilidades_estimadas = clasificador_logreg.predict_proba(x_entrenamiento_logreg)[:,1]\n",
    "probabilidades_estimadas_sin_var = clasificador_logreg_sin_var.predict_proba(np.array([np.ones(n_entrenamiento)]).T)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_verosimilitud = 0\n",
    "for i in range(0,n_entrenamiento):\n",
    "    log_verosimilitud = log_verosimilitud + etiquetas_entrenamiento[i]*np.log(probabilidades_estimadas[i]) + (1-etiquetas_entrenamiento[i])*np.log(1-probabilidades_estimadas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_verosimilitud_sin_var = 0\n",
    "for i in range(0,n_entrenamiento):\n",
    "    log_verosimilitud_sin_var = log_verosimilitud_sin_var + etiquetas_entrenamiento[i]*np.log(probabilidades_estimadas_sin_var[i]) + (1-etiquetas_entrenamiento[i])*np.log(1-probabilidades_estimadas_sin_var[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = -2*(log_verosimilitud_sin_var-log_verosimilitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = 1-chi2.cdf(G,x_entrenamiento.shape[1])\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matriz_V = np.zeros([n_entrenamiento,n_entrenamiento])\n",
    "for i in range(0,n_entrenamiento):\n",
    "    matriz_V[i,i] = probabilidades_estimadas[i]*(1-probabilidades_estimadas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_logreg = clasificador_logreg.coef_\n",
    "matriz_informacion = np.dot(x_entrenamiento_logreg.T,np.dot(matriz_V,x_entrenamiento_logreg))\n",
    "matriz_varianza_w = np.linalg.inv(matriz_informacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estadistico_prueba = w_logreg/np.sqrt(np.diag(matriz_varianza_w ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.7248539 ,  47.81261084, -11.21216776,  -9.8072877 ,\n",
       "        -23.18880611,  -4.51699831, -20.57352632, -11.14402613,\n",
       "         -0.33615705,   6.94728974,  -4.09772927,  -4.21487517,\n",
       "         -5.04357664,  -2.10236908,  -3.34205709,  10.19238052,\n",
       "          3.0660476 ,  -0.88221512,   1.27336193]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estadistico_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_values_EP = 2*(1-norm.cdf(abs(estadistico_prueba)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_significativas = np.where(p_values_EP<0.05,np.ones(estadistico_prueba.size),np.zeros(estadistico_prueba.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_logreg_reducido = np.copy(x_entrenamiento_logreg)\n",
    "for i in range(0,var_significativas.size):\n",
    "    if var_significativas[var_significativas.size-i-1] == 0:\n",
    "        x_logreg_reducido = np.delete(x_logreg_reducido,var_significativas.size-i-1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clasificador_logreg_red = LogisticRegression(solver='sag',max_iter=1000)\n",
    "clasificador_logreg_red = clasificador_logreg_red.fit(x_logreg_reducido,etiquetas_entrenamiento)\n",
    "probabilidades_estimadas_red = clasificador_logreg_red.predict_proba(x_logreg_reducido)[:,1]\n",
    "log_verosimilitud_red = 0\n",
    "for i in range(0,n_entrenamiento):\n",
    "    log_verosimilitud_red = log_verosimilitud_red + etiquetas_entrenamiento[i]*np.log(probabilidades_estimadas_red[i]) + (1-etiquetas_entrenamiento[i])*np.log(1-probabilidades_estimadas_red[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62597159382288525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_red = -2*(log_verosimilitud_red-log_verosimilitud)\n",
    "p_val_red = 1-chi2.cdf(G_red,x_entrenamiento.shape[1]-sum(var_significativas)+1)\n",
    "p_val_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701171875"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prueba_logreg = np.append(np.array([np.ones(n_prueba)]).T,x_prueba,axis=1)\n",
    "puntaje = clasificador_logreg.score(x_prueba_logreg,etiquetas_prueba)\n",
    "puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_logreg_reducido_prueba = np.copy(x_prueba_logreg)\n",
    "for i in range(0,var_significativas.size):\n",
    "    if var_significativas[var_significativas.size-i-1] == 0:\n",
    "        x_logreg_reducido_prueba = np.delete(x_logreg_reducido_prueba,var_significativas.size-i-1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701171875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntaje_red = clasificador_logreg_red.score(x_logreg_reducido_prueba, etiquetas_prueba)\n",
    "puntaje_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
