{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "y_total = np.genfromtxt(\"msd_genre_dataset.txt\",dtype =None,usecols=0,comments=None,delimiter=',',skip_header=10)\n",
    "x_total = np.genfromtxt(\"msd_genre_dataset.txt\",comments=None,delimiter=',',skip_header=10)[:,4:]\n",
    "\n",
    "generos = [b'metal',b'punk',b'dance and electronica']\n",
    "\n",
    "y_raw = []\n",
    "x_raw = []\n",
    "for i in range(0,y_total.size):\n",
    "    if y_total[i] in generos:\n",
    "        y_raw.append(y_total[i])\n",
    "        x_raw.append(x_total[i])\n",
    "        \n",
    "y_raw = np.asarray(y_raw)\n",
    "x_raw = np.asarray(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "x_normalizado = (x_raw - np.mean(x_raw,axis=0))/np.std(x_raw,axis=0)\n",
    "\n",
    "# PCA\n",
    "proporcion_varianza = 0\n",
    "n_componentes = 0\n",
    "while proporcion_varianza < 0.90:\n",
    "    n_componentes = n_componentes + 1\n",
    "    pca = PCA(n_components=n_componentes)\n",
    "    pca = pca.fit(x_normalizado)\n",
    "    proporcion_varianza = np.sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "suma_acumulada_varianza = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "\n",
    "x_preprocesamiento = pca.fit_transform(x_normalizado)\n",
    "xy_preprocesamiento = np.append(x_preprocesamiento,np.array([y_raw]).T,axis=1)\n",
    "\n",
    "# Separacion de datos para prueba y entrenamiento\n",
    "proporcion_prueba_f = 0.2\n",
    "proporcion_prueba_t = 0.1\n",
    "np.random.shuffle(xy_preprocesamiento)\n",
    "n_prueba_f = round(proporcion_prueba_f*y_raw.size)\n",
    "n_prueba_t = round(proporcion_prueba_t*y_raw.size)\n",
    "n_entrenamiento = y_raw.size - n_prueba_f - n_prueba_t\n",
    "datos_prueba_f = xy_preprocesamiento[0:n_prueba_f,:]\n",
    "x_prueba_f = datos_prueba_f[:,0:-1].astype(np.float64)\n",
    "y_prueba_f = datos_prueba_f[:,-1]\n",
    "datos_prueba_t = xy_preprocesamiento[n_prueba_f:n_prueba_f+n_prueba_t,:]\n",
    "x_prueba_t = datos_prueba_t[:,0:-1].astype(np.float64)\n",
    "y_prueba_t = datos_prueba_t[:,-1]\n",
    "datos_entrenamiento = xy_preprocesamiento[n_prueba_f+n_prueba_t:,:]\n",
    "x_entrenamiento = datos_entrenamiento[:,0:-1].astype(np.float64)\n",
    "y_entrenamiento = datos_entrenamiento[:,-1]\n",
    "etiquetas_prueba_f = np.where(y_prueba_f == generos[2], np.ones(n_prueba_f), -np.ones(n_prueba_f))\n",
    "etiquetas_prueba_t = np.where(y_prueba_t == generos[2], np.ones(n_prueba_t), -np.ones(n_prueba_t))\n",
    "etiquetas_entrenamiento = np.where(y_entrenamiento == generos[2], np.ones(n_entrenamiento), -np.ones(n_entrenamiento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes = []\n",
    "clasificadores_2L_NN = []\n",
    "promedio_coefs = []\n",
    "n_n_min = 2\n",
    "n_n_max = 100\n",
    "for n_neuronas in range(n_n_min,n_n_max+1):\n",
    "    clasificador = MLPClassifier(solver='sgd',activation='tanh',alpha=1e-5,\n",
    "                                       hidden_layer_sizes=(n_neuronas,),batch_size=10)\n",
    "    clasificadores_2L_NN.append(clasificador.fit(x_entrenamiento, etiquetas_entrenamiento))\n",
    "    puntajes.append(clasificador.score(x_prueba_t, etiquetas_prueba_t))\n",
    "    promedio_coefs.append(np.average(clasificador.coefs_[0],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(puntajes)\n",
    "plt.savefig('test_3.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.asarray(promedio_coefs)\n",
    "for i in range(0,n_n_max-n_n_min):\n",
    "    plt.plot(np.abs(a[:,i]))\n",
    "plt.savefig('test_coef_3.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
