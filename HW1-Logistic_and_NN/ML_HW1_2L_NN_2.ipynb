{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "y_total = np.genfromtxt(\"msd_genre_dataset.txt\",dtype =None,usecols=0,comments=None,delimiter=',',skip_header=10)\n",
    "x_total = np.genfromtxt(\"msd_genre_dataset.txt\",comments=None,delimiter=',',skip_header=10)[:,4:]\n",
    "\n",
    "generos = [b'metal',b'punk',b'dance and electronica']\n",
    "\n",
    "y_raw = []\n",
    "x_raw = []\n",
    "for i in range(0,y_total.size):\n",
    "    if y_total[i] in generos:\n",
    "        y_raw.append(y_total[i])\n",
    "        x_raw.append(x_total[i])\n",
    "        \n",
    "y_raw = np.asarray(y_raw)\n",
    "x_raw = np.asarray(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "x_normalizado = (x_raw - np.mean(x_raw,axis=0))/np.std(x_raw,axis=0)\n",
    "\n",
    "# PCA\n",
    "proporcion_varianza = 0\n",
    "n_componentes = 0\n",
    "while proporcion_varianza < 0.90:\n",
    "    n_componentes = n_componentes + 1\n",
    "    pca = PCA(n_components=n_componentes)\n",
    "    pca = pca.fit(x_normalizado)\n",
    "    proporcion_varianza = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "suma_acumulada_varianza = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "\n",
    "x_preprocesamiento = pca.fit_transform(x_normalizado)\n",
    "xy_preprocesamiento = np.append(x_preprocesamiento,np.array([y_raw]).T,axis=1)\n",
    "\n",
    "# Separacion de datos para prueba y entrenamiento\n",
    "proporcion_prueba = 0.1\n",
    "np.random.shuffle(xy_preprocesamiento)\n",
    "n_prueba = round(proporcion_prueba*y_raw.size)\n",
    "n_entrenamiento = y_raw.size - n_prueba\n",
    "datos_prueba = xy_preprocesamiento[0:n_prueba,:]\n",
    "x_prueba = datos_prueba[:,0:-1].astype(np.float64)\n",
    "y_prueba = datos_prueba[:,-1]\n",
    "datos_entrenamiento = xy_preprocesamiento[n_prueba:,:]\n",
    "x_entrenamiento = datos_entrenamiento[:,0:-1].astype(np.float64)\n",
    "y_entrenamiento = datos_entrenamiento[:,-1]\n",
    "etiquetas_prueba = np.where(y_prueba == generos[2], np.ones(n_prueba), -np.ones(n_prueba))\n",
    "etiquetas_entrenamiento = np.where(y_entrenamiento == generos[2], np.ones(n_entrenamiento), -np.ones(n_entrenamiento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes = []\n",
    "clasificadores_2L_NN = []\n",
    "promedio_coefs = []\n",
    "n_n_min = 2\n",
    "n_n_max = 1000\n",
    "for n_neuronas in range(n_n_min,n_n_max+1):\n",
    "    clasificador = MLPClassifier(solver='sgd',activation='relu',alpha=1e-5,\n",
    "                                       hidden_layer_sizes=(n_neuronas,),batch_size=10,max_iter=10000)\n",
    "    clasificadores_2L_NN.append(clasificador.fit(x_entrenamiento, etiquetas_entrenamiento))\n",
    "    puntajes.append(clasificador.score(x_prueba_t, etiquetas_prueba_t))\n",
    "    promedio_coefs.append(np.average(clasificador.coefs_[0],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(puntajes)\n",
    "plt.savefig('test_4.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(promedio_coefs)\n",
    "for i in range(0,17):\n",
    "    plt.plot(np.abs(a[:,i]))\n",
    "plt.savefig('test_coef_4.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clasificadores_2L_NN, open(\"saved/clasificadores_2L_NN_1000.p\", \"wb\"))\n",
    "pickle.dump(puntajes, open(\"saved/puntajes_2L_NN_1000.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes_log = []\n",
    "clasificadores_2L_NN_log = []\n",
    "n_n_min_2 = 2\n",
    "n_n_max_2 = 200\n",
    "for n_neuronas in range(n_n_min_2,n_n_max_2+1):\n",
    "    clasificador = MLPClassifier(solver='sgd',activation='logistic',\n",
    "                                       hidden_layer_sizes=(n_neuronas,),batch_size=100,max_iter=10000)\n",
    "    clasificadores_2L_NN_log.append(clasificador.fit(x_entrenamiento, etiquetas_entrenamiento))\n",
    "    puntajes_log.append(clasificador.score(x_prueba_t, etiquetas_prueba_t))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clasificadores_2L_NN_log, open(\"saved/clasificadores_2L_NN_log.p\", \"wb\"))\n",
    "pickle.dump(puntajes_log, open(\"saved/puntajes_2L_NN_log.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(puntajes_log)\n",
    "plt.savefig('test_4_log.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes_log_2 = []\n",
    "clasificadores_2L_NN_log_2 = []\n",
    "for n_neuronas in range(n_n_min_2,n_n_max_2+1):\n",
    "    clasificador = MLPClassifier(solver='sgd',activation='logistic',alpha=1e-4,\n",
    "                                       hidden_layer_sizes=(n_neuronas,),batch_size=100,max_iter=10000)\n",
    "    clasificadores_2L_NN_log_2.append(clasificador.fit(x_entrenamiento, etiquetas_entrenamiento))\n",
    "    puntajes_log_2.append(clasificador.score(x_prueba_t, etiquetas_prueba_t))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(puntajes_log_2)\n",
    "plt.savefig('test_4_log_2.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clasificadores_2L_NN_log_2, open(\"saved/clasificadores_2L_NN_log_2.p\", \"wb\"))\n",
    "pickle.dump(puntajes_log_2, open(\"saved/puntajes_2L_NN_log_2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clasificadores_2L_NN_relu = pickle.load(open(\"saved/clasificadores_2L_NN_1000.p\", \"rb\"))\n",
    "puntajes_2L_NN_relu = pickle.load(open(\"saved/puntajes_2L_NN_1000.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neuronas_optimo_relu = np.argmax(np.asarray(puntajes_2L_NN_relu)) + n_n_min_2\n",
    "n_neuronas_optimo_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entrenamiento_total = np.append(x_entrenamiento,x_prueba_t,axis=0)\n",
    "y_entrenamiento_total = np.append(y_entrenamiento,y_prueba_t,axis=0)\n",
    "etiquetas_entrenamiento_total = np.where(y_entrenamiento_total == generos[2],\n",
    "                                         np.ones(n_entrenamiento+n_prueba_t), -np.ones(n_entrenamiento+n_prueba_t))\n",
    "clasificador_escogido_relu = MLPClassifier(solver='sgd',activation='relu',\n",
    "                                       hidden_layer_sizes=(n_neuronas_optimo_relu,),batch_size=100,max_iter=10000)\n",
    "clasificador_escogido_relu.fit(x_entrenamiento_total, etiquetas_entrenamiento_total)\n",
    "puntajes_c_escogido = clasificador_escogido_relu.score(x_prueba_f, etiquetas_prueba_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89127604166666663"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntajes_c_escogido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes = []\n",
    "clasificadores_2L_NN = []\n",
    "promedio_coefs = []\n",
    "n_n_min = 2\n",
    "n_n_max = 450\n",
    "n = n_n_min\n",
    "while n <= n_n_max:\n",
    "    clasificador = MLPClassifier(solver='sgd',activation='relu',alpha=1e-5,\n",
    "                                       hidden_layer_sizes=(n_neuronas,),batch_size=10,max_iter=10000)\n",
    "    clasificadores_2L_NN.append(clasificador.fit(x_entrenamiento, etiquetas_entrenamiento))\n",
    "    puntajes.append(clasificador.score(x_prueba_t, etiquetas_prueba_t))\n",
    "    promedio_coefs.append(np.average(clasificador.coefs_[0],axis=1))\n",
    "    n = n + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clasificadores_2L_NN, open(\"saved/clasificadores_2L_NN_relu.p\", \"wb\"))\n",
    "pickle.dump(puntajes, open(\"saved/puntajes_2L_NN_relu.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(puntajes)\n",
    "plt.savefig('test_4_relu_450_2.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neuronas_optimo_relu_2 = np.argmax(np.asarray(puntajes))*5 + n_n_min_2\n",
    "n_neuronas_optimo_relu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes_matriz = []\n",
    "n_n_min = 2\n",
    "n_n_max = 102\n",
    "n_l1 = n_n_min\n",
    "while n_l1 <= n_n_max:\n",
    "    n_l2 = n_n_min\n",
    "    puntajes_l2 = []\n",
    "    clasificadores_l2 = []\n",
    "    while n_l2 <= n_n_max:\n",
    "        clasificador = MLPClassifier(solver='lbfgs',activation='relu',hidden_layer_sizes=(n_l1,n_l2))\n",
    "        clasificador = clasificador.fit(x_entrenamiento, etiquetas_entrenamiento)\n",
    "        puntajes_l2.append(clasificador.score(x_prueba, etiquetas_prueba))\n",
    "        n_l2 = n_l2 + 10\n",
    "    puntajes_matriz.append(puntajes_l2)\n",
    "    n_l1 = n_l1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(1-np.asarray(puntajes_matriz).T,1),cmap=plt.cm.hot_r,\n",
    "           extent=[n_n_min,n_n_max,n_n_min,n_n_max])\n",
    "plt.colorbar()\n",
    "plt.xlabel('Neuronas en la segunda capa escondida')\n",
    "plt.ylabel('Neuronas en la primera capa escondida')\n",
    "plt.savefig('puntajes_matriz_2.png',dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(puntajes_matriz, open(\"saved/puntajes_matriz_2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del clasificador\n",
    "puntajes_matriz_2 = []\n",
    "n_n_min = 2\n",
    "n_n_max = 16\n",
    "n_n_max_2 = 102\n",
    "n_c1 = n_n_min\n",
    "while n_c1 <= n_n_max:\n",
    "    n_c2 = n_n_min\n",
    "    puntajes_c2 = []\n",
    "    while n_l2 <= n_n_max_2:\n",
    "        clasificador = MLPClassifier(solver='lbfgs',activation='relu',hidden_layer_sizes=(n_l1,n_l2))\n",
    "        puntajes = cross_val_score(clasificador, x_entrenamiento, etiquetas_entrenamiento, cv = 4, n_jobs = 2)\n",
    "        puntajes_c2.append(puntajes)\n",
    "        n_c2 = n_c2 + 4\n",
    "    puntajes_matriz_2.append(puntajes_c2)\n",
    "    n_c1 = n_c1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
